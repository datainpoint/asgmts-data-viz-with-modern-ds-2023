{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Data Visualization with Modern Data Science\n",
    "\n",
    "> Assignment 6\n",
    "\n",
    "Yao-Jen Kuo <yaojenkuo@ntu.edu.tw> from [DATAINPOINT](https://www.datainpoint.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Instructions\n",
    "\n",
    "- Write down your solution between comments `### BEGIN SOLUTION` and `### END SOLUTION`.\n",
    "- Running tests to see if your solutions are right:\n",
    "    - Runtime -> Restart and run all.\n",
    "- When you are ready to submit, click File -> Download -> Download `.py`.\n",
    "\n",
    "![](https://i.imgur.com/Y1BcDdx.png)\n",
    "\n",
    "- Open a new Colab in a private window, upload the script and run tests again before submission to make sure the script is executable in a fresh new Colab.\n",
    "\n",
    "![](https://i.imgur.com/ojlvbds.png)\n",
    "\n",
    "- Upload to the Assignment session on NTU COOL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"UID_ISO_FIPS_LookUp_Table.csv\", \"02-28-2023.csv\", \"imdb_top250.csv\"]\n",
    "for file_name in file_names:\n",
    "    file_url = f\"https://raw.githubusercontent.com/datainpoint/data-viz-with-modern-ds-2023/main/{file_name}\"\n",
    "    r = requests.get(file_url)\n",
    "    with open(file_name , 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a Python function `import_lookup_table_and_daily_report()` which imports `UID_ISO_FIPS_LookUp_Table.csv` and `02-28-2023.csv` in working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_lookup_table_and_daily_report() -> tuple:\n",
    "    \"\"\"\n",
    "    >>> lookup_table, daily_report = import_lookup_table_and_daily_report()\n",
    "    >>> type(lookup_table)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> type(daily_report)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> lookup_table.shape\n",
    "    (4321, 12)\n",
    "    >>> daily_report.shape\n",
    "    (4016, 14)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a Python function `inner_join_lookup_table_and_daily_report()` which inner joins `UID_ISO_FIPS_LookUp_Table.csv` and `02-28-2023.csv` on `Combined_Key` in working directory. Select specified columns from the joined result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_join_lookup_table_and_daily_report() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> lookup_table_and_daily_report = inner_join_lookup_table_and_daily_report()\n",
    "    >>> type(lookup_table_and_daily_report)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> lookup_table_and_daily_report.shape\n",
    "    (4014, 9)\n",
    "    >>> print(lookup_table_and_daily_report)\n",
    "              Admin2 Province_State Country_Region             Combined_Key   \n",
    "    0            NaN            NaN    Afghanistan              Afghanistan  \\\n",
    "    1            NaN            NaN        Albania                  Albania   \n",
    "    2            NaN            NaN     Antarctica               Antarctica   \n",
    "    3            NaN            NaN        Algeria                  Algeria   \n",
    "    4            NaN            NaN        Andorra                  Andorra   \n",
    "    ...          ...            ...            ...                      ...   \n",
    "    4009  Sweetwater        Wyoming             US  Sweetwater, Wyoming, US   \n",
    "    4010       Teton        Wyoming             US       Teton, Wyoming, US   \n",
    "    4011       Uinta        Wyoming             US       Uinta, Wyoming, US   \n",
    "    4012    Washakie        Wyoming             US    Washakie, Wyoming, US   \n",
    "    4013      Weston        Wyoming             US      Weston, Wyoming, US   \n",
    "\n",
    "          Confirmed  Deaths  Population  Incident_Rate  Case_Fatality_Ratio  \n",
    "    0        209322    7896  38928341.0     537.711073             3.772179  \n",
    "    1        334391    3598   2877800.0   11619.674752             1.075986  \n",
    "    2            11       0         NaN            NaN             0.000000  \n",
    "    3        271441    6881  43851043.0     619.006941             2.534989  \n",
    "    4         47866     165     77265.0   61950.430337             0.344712  \n",
    "    ...         ...     ...         ...            ...                  ...  \n",
    "    4009      12499     139     42343.0   29518.456415             1.112089  \n",
    "    4010      12130      16     23464.0   51696.215479             0.131904  \n",
    "    4011       6401      43     20226.0   31647.384555             0.671770  \n",
    "    4012       2750      50      7805.0   35233.824471             1.818182  \n",
    "    4013       1905      23      6927.0   27501.082720             1.207349  \n",
    "\n",
    "    [4014 rows x 9 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a Python function `create_combined_keys()` which replicate the column `Combined_Key` but concatenating `Country_Region`, `Province_State`, and `Admin2` with different order and a different separator `-` from the output of `inner_join_lookup_table_and_daily_report()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_keys() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> combined_keys = create_combined_keys()\n",
    "    >>> type(combined_keys)\n",
    "    pandas.core.series.Series\n",
    "    >>> combined_keys.shape\n",
    "    (4014,)\n",
    "    >>> combined_keys\n",
    "    0                 Afghanistan\n",
    "    1                     Albania\n",
    "    2                  Antarctica\n",
    "    3                     Algeria\n",
    "    4                     Andorra\n",
    "                    ...          \n",
    "    4009    US-Wyoming-Sweetwater\n",
    "    4010         US-Wyoming-Teton\n",
    "    4011         US-Wyoming-Uinta\n",
    "    4012      US-Wyoming-Washakie\n",
    "    4013        US-Wyoming-Weston\n",
    "    Name: Country_Region, Length: 4014, dtype: object\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Define a Python function `calculate_incident_rate_by_country_region()` which replicate the column `Incident_Rate` from the output of `inner_join_lookup_table_and_daily_report()` but calculate in country-level.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Incident Rate} = \\frac{\\text{Confirmed}}{\\text{Population}} \\times 100000\n",
    "\\end{equation}\n",
    "\n",
    "PS. Exclude data with 0 population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_incident_rate_by_country_region() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> incident_rate_by_country_region = calculate_incident_rate_by_country_region()\n",
    "    >>> type(incident_rate_by_country_region)\n",
    "    pandas.core.series.Series\n",
    "    >>> incident_rate_by_country_region.shape\n",
    "    (196,)\n",
    "    >>> incident_rate_by_country_region\n",
    "    Country_Region\n",
    "    Afghanistan             537.711073\n",
    "    Albania               11619.674752\n",
    "    Algeria                 619.006941\n",
    "    Andorra               61950.430337\n",
    "    Angola                  320.252363\n",
    "                              ...     \n",
    "    Vietnam               11842.084243\n",
    "    West Bank and Gaza    13784.956961\n",
    "    Yemen                    40.048994\n",
    "    Zambia                 1865.822568\n",
    "    Zimbabwe               1775.700035\n",
    "    Length: 196, dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Define a Python function `find_countries_incident_rate()` which retrieves the data given a `country_list` from the output of `calculate_incident_rate_by_country_region()`.\n",
    "\n",
    "```python\n",
    "country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_countries_incident_rate() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> countries_incident_rate = find_countries_incident_rate()\n",
    "    >>> type(countries_incident_rate)\n",
    "    pandas.core.series.Series\n",
    "    >>> countries_incident_rate.shape\n",
    "    (11,)\n",
    "    >>> countries_incident_rate\n",
    "    Country_Region\n",
    "    Canada            12034.670299\n",
    "    Japan             26335.922781\n",
    "    US                31128.127922\n",
    "    United Kingdom    36640.306538\n",
    "    Singapore         38055.837068\n",
    "    Taiwan*           41865.185358\n",
    "    Australia         44644.520556\n",
    "    Germany           45900.900452\n",
    "    New Zealand       45951.308542\n",
    "    France            58459.281558\n",
    "    Korea, South      59540.664028\n",
    "    dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Define a Python function `calculate_case_fatality_ratio_by_country_region()` which replicate the column `Case_Fatality_Ratio` from the output of `inner_join_lookup_table_and_daily_report()` but calculate in country-level.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Case Fatality Ratio} = \\frac{\\text{Deaths}}{\\text{Confirmed}} \\times 100\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_case_fatality_ratio_by_country_region() -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    >>> case_fatality_ratio_by_country_region = calculate_case_fatality_ratio_by_country_region()\n",
    "    >>> type(case_fatality_ratio_by_country_region)\n",
    "    pandas.core.series.Series\n",
    "    >>> case_fatality_ratio_by_country_region.shape\n",
    "    (201,)\n",
    "    >>> case_fatality_ratio_by_country_region\n",
    "    Country_Region\n",
    "    Afghanistan              3.772179\n",
    "    Albania                  1.075986\n",
    "    Algeria                  2.534989\n",
    "    Andorra                  0.344712\n",
    "    Angola                   1.836492\n",
    "                              ...    \n",
    "    West Bank and Gaza       0.811686\n",
    "    Winter Olympics 2022     0.000000\n",
    "    Yemen                   18.074508\n",
    "    Zambia                   1.182757\n",
    "    Zimbabwe                 2.145718\n",
    "    Length: 201, dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Define a Python function named `unify_countries_ir_and_cfr()` which unifies the incident rate and case fatality given a `country_list`.\n",
    "\n",
    "```python\n",
    "country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_countries_ir_and_cfr() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> countries_ir_and_cfr = unify_countries_ir_and_cfr()\n",
    "    >>> type(countries_ir_and_cfr)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> countries_ir_and_cfr.shape\n",
    "    (11, 3)\n",
    "    >>> print(countries_ir_and_cfr)\n",
    "        Country_Region  Incident_Rate  Case_Fatality_Ratio\n",
    "    0        Singapore   38055.837068             0.077345\n",
    "    1     Korea, South   59540.664028             0.111341\n",
    "    2      New Zealand   45951.308542             0.114355\n",
    "    3        Australia   44644.520556             0.170442\n",
    "    4          Taiwan*   41865.185358             0.177235\n",
    "    5            Japan   26335.922781             0.217879\n",
    "    6           France   58459.281558             0.416811\n",
    "    7          Germany   45900.900452             0.440374\n",
    "    8   United Kingdom   36640.306538             0.897117\n",
    "    9               US   31128.127922             1.082642\n",
    "    10          Canada   12034.670299             1.116822\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Define a Python function `melt_countries_ir_cfr()` which transforms the output of `unify_countries_ir_and_cfr` from wide format to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_countries_ir_cfr() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> countries_ir_cfr_long = melt_countries_ir_cfr()\n",
    "    >>> type(countries_ir_cfr_long)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> countries_ir_cfr_long.shape\n",
    "    (22, 3)\n",
    "    >>> print(countries_ir_cfr_long)\n",
    "        Country_Region             Variable         Value\n",
    "    0        Singapore  Case_Fatality_Ratio      0.077345\n",
    "    1     Korea, South  Case_Fatality_Ratio      0.111341\n",
    "    2      New Zealand  Case_Fatality_Ratio      0.114355\n",
    "    3        Australia  Case_Fatality_Ratio      0.170442\n",
    "    4          Taiwan*  Case_Fatality_Ratio      0.177235\n",
    "    5            Japan  Case_Fatality_Ratio      0.217879\n",
    "    6           France  Case_Fatality_Ratio      0.416811\n",
    "    7          Germany  Case_Fatality_Ratio      0.440374\n",
    "    8   United Kingdom  Case_Fatality_Ratio      0.897117\n",
    "    9               US  Case_Fatality_Ratio      1.082642\n",
    "    10          Canada  Case_Fatality_Ratio      1.116822\n",
    "    11          Canada        Incident_Rate  12034.670299\n",
    "    12           Japan        Incident_Rate  26335.922781\n",
    "    13              US        Incident_Rate  31128.127922\n",
    "    14  United Kingdom        Incident_Rate  36640.306538\n",
    "    15       Singapore        Incident_Rate  38055.837068\n",
    "    16         Taiwan*        Incident_Rate  41865.185358\n",
    "    17       Australia        Incident_Rate  44644.520556\n",
    "    18         Germany        Incident_Rate  45900.900452\n",
    "    19     New Zealand        Incident_Rate  45951.308542\n",
    "    20          France        Incident_Rate  58459.281558\n",
    "    21    Korea, South        Incident_Rate  59540.664028\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Define a Python function named `import_imdb_top250()` which imports `imdb_top250.csv` in working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_imdb_top250() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> imdb_top250 = import_imdb_top250()\n",
    "    >>> type(imdb_top250)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> imdb_top250.shape\n",
    "    (250, 5)\n",
    "    >>> print(imdb_top250)\n",
    "         Unnamed: 0                          Rank & Title  IMDb Rating   \n",
    "    0           NaN  1.  The Shawshank Redemption  (1994)          9.2  \\\n",
    "    1           NaN             2.  The Godfather  (1972)          9.2   \n",
    "    2           NaN           3.  The Dark Knight  (2008)          9.0   \n",
    "    3           NaN     4.  The Godfather Part II  (1974)          9.0   \n",
    "    4           NaN              5.  12 Angry Men  (1957)          9.0   \n",
    "    ..          ...                                   ...          ...   \n",
    "    245         NaN           246.  Life of Brian  (1979)          8.0   \n",
    "    246         NaN          247.  The Iron Giant  (1999)          8.0   \n",
    "    247         NaN                248.  The Help  (2011)          8.0   \n",
    "    248         NaN                 249.  Aladdin  (1992)          8.0   \n",
    "    249         NaN      250.  Dances with Wolves  (1990)          8.0   \n",
    "\n",
    "                                Your Rating  Unnamed: 4  \n",
    "    0    12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    1    12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    2    12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    3    12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    4    12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    ..                                  ...         ...  \n",
    "    245  12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    246  12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    247  12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    248  12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "    249  12345678910 NOT YET RELEASED  Seen         NaN  \n",
    "\n",
    "    [250 rows x 5 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define a Python function named `tidy_imdb_top250()` that is able to tidy the dataframe obtained from the previous question into a desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_imdb_top250() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    >>> tidied_imdb_top250 = tidy_imdb_top250()\n",
    "    >>> type(tidied_imdb_top250)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> tidied_imdb_top250.shape\n",
    "    (250, 4)\n",
    "    >>> print(tidied_imdb_top250)\n",
    "         rank                     title release_year  rating\n",
    "    0       1  The Shawshank Redemption         1994     9.2\n",
    "    1       2             The Godfather         1972     9.2\n",
    "    2       3           The Dark Knight         2008     9.0\n",
    "    3       4     The Godfather Part II         1974     9.0\n",
    "    4       5              12 Angry Men         1957     9.0\n",
    "    ..    ...                       ...          ...     ...\n",
    "    245   246             Life of Brian         1979     8.0\n",
    "    246   247            The Iron Giant         1999     8.0\n",
    "    247   248                  The Help         2011     8.0\n",
    "    248   249                   Aladdin         1992     8.0\n",
    "    249   250        Dances with Wolves         1990     8.0\n",
    "\n",
    "    [250 rows x 4 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Running tests\n",
    "\n",
    "Assignment session is finished, click Runtime -> Restart and run all to run the following tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAssignmentSix(unittest.TestCase):\n",
    "    def test_01_import_lookup_table_and_daily_report(self):\n",
    "        lookup_table, daily_report = import_lookup_table_and_daily_report()\n",
    "        self.assertIsInstance(lookup_table, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lookup_table.shape, (4321, 12))\n",
    "        self.assertIsInstance(daily_report, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(daily_report.shape, (4016, 14))\n",
    "    def test_02_inner_join_lookup_table_and_daily_report(self):\n",
    "        lookup_table_and_daily_report = inner_join_lookup_table_and_daily_report()\n",
    "        self.assertIsInstance(lookup_table_and_daily_report, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lookup_table_and_daily_report.shape[1], 9)\n",
    "    def test_03_create_combined_keys(self):\n",
    "        combined_keys = create_combined_keys()\n",
    "        self.assertIsInstance(combined_keys, pd.core.series.Series)\n",
    "        self.assertIn(\"Afghanistan\", combined_keys.values)\n",
    "        self.assertIn(\"Albania\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Uinta\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Washakie\", combined_keys.values)\n",
    "        self.assertIn(\"US-Wyoming-Weston\", combined_keys.values)\n",
    "    def test_04_calculate_incident_rate_by_country_region(self):\n",
    "        incident_rate_by_country_region = calculate_incident_rate_by_country_region()\n",
    "        self.assertIsInstance(incident_rate_by_country_region, pd.core.series.Series)\n",
    "        self.assertIn(\"Afghanistan\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Albania\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Yemen\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Zambia\", incident_rate_by_country_region.index)\n",
    "        self.assertIn(\"Zimbabwe\", incident_rate_by_country_region.index)\n",
    "    def test_05_find_countries_incident_rate(self):\n",
    "        countries_incident_rate = find_countries_incident_rate()\n",
    "        self.assertIsInstance(countries_incident_rate, pd.core.series.Series)\n",
    "        self.assertEqual(countries_incident_rate.shape, (11,))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_incident_rate.index)\n",
    "    def test_06_calculate_case_fatality_ratio_by_country_region(self):\n",
    "        case_fatality_ratio_by_country_region = calculate_case_fatality_ratio_by_country_region()\n",
    "        self.assertIsInstance(case_fatality_ratio_by_country_region, pd.core.series.Series)\n",
    "        self.assertIn(\"Afghanistan\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Albania\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Yemen\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Zambia\", case_fatality_ratio_by_country_region.index)\n",
    "        self.assertIn(\"Zimbabwe\", case_fatality_ratio_by_country_region.index)\n",
    "    def test_07_unify_countries_ir_and_cfr(self):\n",
    "        countries_ir_and_cfr = unify_countries_ir_and_cfr()\n",
    "        self.assertIsInstance(countries_ir_and_cfr, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(countries_ir_and_cfr.shape, (11, 3))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_ir_and_cfr[\"Country_Region\"].values)\n",
    "    def test_08_melt_countries_ir_cfr(self):\n",
    "        countries_ir_cfr_long = melt_countries_ir_cfr()\n",
    "        self.assertIsInstance(countries_ir_cfr_long, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(countries_ir_cfr_long.shape, (22, 3))\n",
    "        country_list = [\"US\", \"United Kingdom\", \"France\", \"Germany\", \"Canada\", \"Korea, South\", \"Japan\", \"Singapore\", \"Australia\", \"Taiwan*\", \"New Zealand\"]\n",
    "        for country in country_list:\n",
    "            self.assertIn(country, countries_ir_cfr_long[\"Country_Region\"].unique())\n",
    "        self.assertIn(\"Case_Fatality_Ratio\", countries_ir_cfr_long.iloc[:, 1].unique())\n",
    "        self.assertIn(\"Incident_Rate\", countries_ir_cfr_long.iloc[:, 1].unique())\n",
    "    def test_09_import_imdb_top250(self):\n",
    "        imdb_top250 = import_imdb_top250()\n",
    "        self.assertIsInstance(imdb_top250, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(imdb_top250.shape, (250, 5))\n",
    "    def test_10_tidy_imdb_top250(self):\n",
    "        tidied_imdb_top250 = tidy_imdb_top250()\n",
    "        self.assertIsInstance(tidied_imdb_top250, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(tidied_imdb_top250.shape, (250, 4))\n",
    "        self.assertIn(\"The Shawshank Redemption\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"The Godfather\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"The Dark Knight\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"Top Gun: Maverick\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertIn(\"Dances with Wolves\", tidied_imdb_top250.iloc[:, 1].values)\n",
    "        self.assertEqual(tidied_imdb_top250.iloc[:, 0].nunique(), 250)\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestAssignmentSix)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You've got {} successes among {} questions.\".format(number_of_successes, number_of_test_runs))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
